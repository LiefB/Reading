[TOC]
#Parameter Server
##0.Abstract 
    数据和工作负载在worker节点、server节点维护全局共享参数(向量或矩阵)
    异步数据通信
    灵活的一致性模型
    弹性的扩展能力
    持续的容错


##1.Introduction
    分布式优化和推理成为了大规模机器学习的先决条件，单机已无法解决快速增长的数据和参数。
    训练数据的数量可能达到1TB到1PB之间，而训练过程中的参数可能会达到10^9~10^12，且这些共享参数需要被所有worker节点频繁访问，挑战如下：
        巨量参数，需要大量网络带宽；
        迭代计算，由于synchronize barriers，最慢的机器会拖慢整体；
        容错

###1.1 Contributions
    提供5个特征：
        ①高效通信：异步通信模型；
        ②灵活一致性模型：隐藏了同步的代价和延迟；
        ③弹性可扩展：动态扩容；
        ④容错和持久性：Vector clocks保证了网络分区和失败后的良好表现；
        ⑤易用性：用向量和矩阵表示全局共享参数；

###1.2 Engineering Challenges
    每个server节点只维护一部分参数，每个worker节点也只请求一部分参数；
    2个挑战：
        ①Communication：
            参数可以表示成KV对，但每个更新都发送KV操作开销太大；
            许多机器学习算法的参数可以用向量、矩阵、张量表示，每次更新workers只需发送向量或矩阵的一部分即可；
        ②FaultTollerance:
            Live replication of parameters between servers supports hot failover；
            continuous faulttolerance；

###1.3 Related Work
    第一代：使用memcached(key, value) 键值对存储作为同步机制；YahooLDA改进这个机制，增加了一个专门的服务器，提供用户可自定义的更新操作(set, get, update)；
    第二代：用bounded delay模型改进YahooLDA，但进一步限制了worker线程模型；
    第三代：能够解决这些局限性。

    parameter server与通用分布式系统的区别：
        通用的分布式系统通常都是：每次迭代都强制同步，通常在几十个节点上，它们的性能可以表现的很好，但是在大规模集群中，这样的每次迭代强制同步的机制会因为木桶效应变得很慢；
        Mahout基于Hadoop，MLI基于Spark，它们（Spark与MLI）采用的都是Iterative MapReduce的架构。它们能够保持迭代之间的状态，并且执行策略也更加优化了。但是，由于这两种方法都采用同步迭代的通信方式，容易因为个别机器的低性能导致全局性能的降低。
    
        为了解决这个问题，Graphlab采用图形抽象的方式进行异步调度通信。但是它缺少了MapReduce-Based的弹性扩展性，并且它使用粗粒度的snapshots来进行恢复，这两点都会阻碍到可扩展性。parameter server正是吸取Graphlab异步机制的优势，并且解决了其在可扩展性方面的劣势；
        Piccolo用了一个策略来共享和聚合状态：Workers本地pre-aggregate state，然后将updates传输给Server；


##2.Machine Learning
    机器学习广泛使用在：互联网搜索、爬虫监测、推荐系统、计算广告、文档分析；
    训练数据：特征抽取、目标函数、学习；

###2.1 Goals
    objective function；
    迭代计算直到最优或收敛；
    巨大的训练数据集和模型参数：trillions of trillion-length feature vectors and dimensions；

###2.2 Risk Minimization
    Risk是指对预测偏差的度量；
    训练数据过少、模型太复杂 --> 过拟合，模型太简单 --> 抓取不到正确决策的相关信息；
    经验风险函数 = 损失函数 + 模型复杂度；
    
    例子：分布式梯度下降

###2.3 Generative Models
    unsupervised algorithms
    
    例子：主题模型


##3.Architecture
    在parameter server中，每个server只负责分到的部分参数（servers共同维持一个全局的共享参数），每个worker也只分到部分数据和处理任务；
    
    1个Server Group：n个server节点、1个server manager
        server节点：
            每个server节点只负责全局共享参数的一部分，server节点间相互通信以备份参数增强可靠性或迁移参数增强可扩展性；
        server manager节点：
            拥有所有server节点的元数据(如各个节点的存活状态，参数分区的分配情况等)的一致性视图；
    
    n个Worker Group：每个group有n个worker节点、1个task scheduler
        worker节点：
            每个worker节点只存储训练数据的一部分以进行本地统计计算(如梯度)；worker节点之间没有通信，只与server节点进行通信以更新和拉取共享的参数。
        task scheduler：
            每个worker group有一个task scheduler，负责向worker分配任务，并且监控worker的运行情况。当有新的worker加入或者退出，task scheduler负责重新分配未完成的任务。

###3.1 (Key, Value) Vectors
    最小化损失函数的问题，key就是featureID，而value就是它的权值；
    LDA问题，key是wordID+topicID，而value就是一个计数值；
    keys are ordered：
        将参数看作(K,V)对，赋予他们向量、矩阵的语义，不存在的keys为0；

###3.2 Range Push and Pull
    workers与servers之间通过push和pull来通信。workers通过push将计算好的参数发送到server，然后通过pull从server更新参数。
    为了提高计算性能和带宽效率，parameter server允许用户使用Range Push 和 Range Pull操作：
        假设R是需要push或pull的key的range
        w.push(R, dest)
        w.pull(R, dest) 

###3.3 User-Defined Functions on Server
    server节点除了从workers聚合数据，还可以执行用户定义的函数（server节点有更完整的共享参数的最新信息）；

###3.4 Asynchronous Tasks and Dependency
    rpc发起tasks，可以是worker对servers发起的push、pull，也可以是scheduler发起的用户自定义函数。tasks可能含有任意数量的子tasks；
    任务异步执行；
    调用者标记一个任务已完成，当它收到被调用者的回复（用户自定义函数的返回、pull的键值对请求、空ack）；
    被调用者标记一个任务已完成，当它的调用已返回并且所有的子任务已完成；
    
    execute-after-finished依赖：一个任务依赖于另一个任务的执行的完成，如：
        等所有worker的参数都被聚合了，server再聚合参数；
        支持灵活的一致性模型；

###3.5 Flexible Consistency
    独立的任务通过并行使用CPU、磁盘、网络带宽提高了系统的效率，但这可能会导致节点间数据的不一致性，从而降低算法的收敛速率；
    系统性能与算法收敛速率之间存在一个trade-off：
        算法对于参数非一致性的敏感度；
        训练数据特征之间的关联度；
        硬盘的存储容量；
    
    考虑到用户使用的时候会有不同的情况，parameter server为用户提供了多种任务依赖方式：
        ①Sequential：
            任务顺序执行，前一个任务结束后一个任务才能开始，也称为Bulk Synchronous Processing（BSP）；
        ②Eventual：
            所有任务可以并行开始；
        ③Bounded Delay：
            是sequential与eventual之间的trade-off，可以设置一个τ作为最大的延时时间。也就是说，只有 > τ 之前的任务都被完成了，才能开始一个新的任务；
            τ=0的情况就是 Sequential； 
            τ=∞的情况就是 Eventual；

###3.6 User-defined Filters
    为了弥补基于调度器的流控，parameter server支持用户定义的过滤器来选择性地同步个人键值对，实现一个任务的数据一致性的良好粒度的控制；
    如significantly modified filter；


##4.Implementation

