#2018-12-07
    流处理的checkpoint：
        pipeline snapshot（Distributed Snapshotting）
        “state”！
    微批处理Spark Streaming
        1. RDD checkpoint
            不是state，而是对RDD lineage checkpoint
        2. epoch checkpoint
            Streaming的state，一批好了下一批才能进来

    计算和容错：pipeline
        非阻塞，无延迟
    流处理：pipeline比blocking好
    批处理：pipeline不一定比blocking好
    Flink对批处理有Optimizer

#2018-12-14
    延迟：①水位线内；②水位线外(丢弃；到达时窗口还在则repair)
    
    ZooKeeper：JobManager HA，Flink迭代双屏障同步中间状态
    
    MapReduce、Spark迭代靠外部Loop
    
    External State Backend 与 Local State Backend：
        External State Backend不需要I/O:
            failure节点需要reassign，因此无论如何都需要I/O；
            alive节点：
                LocalMemory，若内存能hold住，但cancel后memory没了(但理论上能保存);
                FSState，磁盘I/O；
                RocksDB，若还在内存中，还没flush到磁盘，则不需要I/O；

#2018-12-21
    Reconfigration如何减少I/O？
        ①reconfigration会改变分区；
        ②内存中状态如何hold住？
        flink keyed group尽量减少需要改变分区的数量
    
    幂等and事务Sink
        幂等：简单再提交一次；
        事务：分布式中每个节点只知道自己成功与否，因此需要引入协调者进行2PC(Flink中等所有operator都汇报自己成功后才真正提交)；
    
    Message Passing Model
        异步and批：减少消息传递所需建立连接次数以及报文冗余信息；
    
    Giraph、GraphLab、Giraph++、X-Stream：
        Giraph：vertex-centirc
        Giraph++：graph-centric
        X-Stream：edge-centric
        Giraph：基于BSP
        GraphLab：异步不需要synchronize supersteps，打破BSP模型

#2018-12-28
    通过co-partition避免shuffle？
    窄依赖的join
    
    关系型数据库查询优化
        并、交、叉、选择、投影、连接
    SystemML查询优化
        矩阵加减乘除
    
    机器学习3要素：
        模型-参数：线性、非线性
        策略-数据：线性回归目标使得误差最小
        算法-计算：如何使误差达到最小(如梯度下降)
    
    从编程和实现角度看：
        以计算为中心
            注重计算逻辑
            SystemML 线性回归
        以数据为中心
            数据之间有关系
            GraphLab 
        以模型为中心
            有很多参数
            parameter server 深度神经网络
    
    凸优化
    
    26号寒假
    20-25分钟，讲为主，可打断。