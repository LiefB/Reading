[TOC]
#MapReduce-《大数据技术原理与应用》
##1.概述
###1.1 分布式并行编程
    过去：单指令、单数据流顺序执行 --> 提高CPU性能
    现在：摩尔定律失效,分布式并行编程 --> 向集群中增加新的计算节点

###1.2 MapReduce模型简介
    ①前提条件：待处理数据集可以分解成许多小的数据集，且每个小数据集可以完全并行处理。
    ②分布式文件系统中的数据切分成多个独立的小数据块，被多个Map任务并行处理，Map输出的中间结果作为Reduce的输入。
    ③“移动计算比移动数据更经济”
    ④Master/Slave架构，Master上运行JobTracker，Slave上运行TaskTracker。

###1.3 Map和Reduce函数
    编程容易，因为程序员只需关注Map和Reduce函数，而无需关注分布式存储、工作调度、负载均衡、容错处理、网络通信等问题。
    Map        <k1,v1>           List(<k2,v2>)
    Reduce     <k2,List(v2)>     <k3,v3>
    Map任务的每个键都会经过Hash函数计算，并根据哈希结果将该键值对输入相应的Reduce任务来处理。

##2.MapReduce的工作流程
###2.1 工作流程概述
    核心思想：“分而治之”。将一大数据集拆分成多个小数据块在多台机器上并行处理。移动计算，计算和数据可以放在一起运行，避免额外的数据传输开销。

###2.2 MapReduce各执行阶段
    ①InputFormat预处理，如输入格式是否符合输入定义；将输入文件切分为逻辑上的多个InputSplit(位置+长度)；
    ②RecordReader（RR）根据InputSplit信息加载数据并转换为适合Map任务读取的键值对，输入给Map任务；
    ③Map任务根据用户自定义映射规则，输出<key,value>中间结果；
    ④Shuffle：对Map的输出进行分区、排序（Sort）、合并（Combine）、归并（Merge），得到<key,value-list>形式的中间结果，再交给相应的Reduce处理；
    ⑤Reduce执行用户定义逻辑，输出结果给OutputFormat模块；
    ⑥OutputFormat模块验证输出目录是否已经存在以及输出结果是否符合配置文件中的配置类型，都满足，则输出Reduce结果到分布式文件系统。

###2.3 Shuffle过程详解
    Map端
        ①输入数据执行Map任务；
        ②输出（序列化）写入缓存；
        ③溢写(分区、排序、合并(减少网络传输数据量))；
        ④归并多个溢写文件（溢写文件数量超过设置的参数时触发）；
        JobTracker监测Map任务的执行，检测到一个Map任务完成就会立即通知相应的Reduce来领取数据。

    Reduce端
        ①领取数据；
        ②归并溢写文件数据(默认对键值对排序，一次归并的文件数量由参数决定)；
        ③把数据输入Reduce任务（多轮归并后得到若干个大文件不会继续归并成一个，直接输入Reduce任务以减小磁盘读写开销）；