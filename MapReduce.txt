[TOC]
#MapReduce
##1.概述
###1.1 分布式并行编程
    过去：单指令、单数据流顺序执行 --> 提高CPU性能
    现在：摩尔定律失效,分布式并行编程 --> 向集群中增加新的计算节点

###1.2 MapReduce模型简介
    ①前提条件：待处理数据集可以分解成许多小的数据集，且每个小数据集可以完全并行处理。
    ②分布式文件系统中的数据切分成多个独立的小数据块，被多个Map任务并行处理，Map输出的中间结果作为Reduce的输入。
    ③“移动计算比移动数据更经济”
    ④Master/Slave架构，Master上运行JobTracker，Slave上运行TaskTracker。

###1.3 Map和Reduce函数
    (受函数式编程启发)编程容易，因为程序员只需关注Map和Reduce函数，而无需关注分布式存储、工作调度、负载均衡、容错处理、网络通信等问题。
    Map        <k1,v1>           List(<k2,v2>)
    Reduce     <k2,List(v2)>     <k3,v3>
    Map任务的每个键都会经过Hash函数计算，并根据哈希结果将该键值对输入相应的Reduce任务来处理。


##2.MapReduce的工作流程
###2.1 工作流程概述
    核心思想：“分而治之”。将一大数据集拆分成多个小数据块在多台机器上并行处理。移动计算，计算和数据可以放在一起运行，避免额外的数据传输开销。

###2.2 MapReduce各执行阶段
    ①InputFormat预处理，如输入格式是否符合输入定义；将输入文件切分为逻辑上的M个InputSplit(位置+长度)；
    ②RecordReader（RR）根据InputSplit信息加载数据并转换为适合Map任务读取的键值对，输入给N个Map任务；
    ③N个Map任务根据用户自定义映射规则，输出<key,value>中间结果；
    ④Shuffle：对Map的输出进行分区、排序（Sort）、合并（Combine）、归并（Merge），得到<key,value-list>形式的中间结果，再交给相应的Reduce处理；
    ⑤R个Reduce执行用户定义逻辑，输出结果给OutputFormat模块；
    ⑥OutputFormat模块验证输出目录是否已经存在以及输出结果是否符合配置文件中的配置类型，都满足，则输出Reduce结果到分布式文件系统。

###2.3 Shuffle过程详解
    Map端
        ①输入数据执行Map任务；
        ②输出（序列化）写入缓存；
        ③溢写(分区、排序、合并(减少网络传输数据量))；
        ④归并多个溢写文件（溢写文件数量超过设置的参数时触发）；
        JobTracker监测Map任务的执行，检测到一个Map任务完成就会立即通知相应的Reduce来领取数据。

    Reduce端
        ①领取数据；
        ②归并溢写文件数据(默认对键值对排序，一次归并的文件数量由参数决定)；
        ③把数据输入Reduce任务（多轮归并后得到若干个大文件不会继续归并成一个，直接输入Reduce任务以减小磁盘读写开销）；


##3.容错
###3.1 工作节点故障
    已完成的Map任务需要重新执行，因为输出的中间结果存储在故障机器的磁盘上不能被访问了；
    已完成的Reduce任务不需要重新执行，因为输出已存储在一个全局文件系统中。

###3.2 主节点故障
    从检查点恢复。


##4.Locality
    GFS将输入文件切分成64MB大小的块，并且将每个块的多份副本存储在不同的机器上。
    MapReduce的master获取所有输入文件的位置信息，然后将Map任务调度到有相应输入文件副本的机器上（或最近的机器），以节省网络带宽。


##5.任务粒度
    M个Map任务、R个Reduce任务，比worker machine数量多得多。
    
    实际中M和R有实用范围，因为master要做O(M+R)个调度决策，且在内存中保存O(M*R)个状态。
        
    且R通常受限于用户，因为各个Reduce任务要输出到独立的各个输出文件中。实际中，我们会选择M使得每个输入文件大概16MB到64MB（使Locality达到最优）；选择R为worker machine的一个小的倍数。
    (M=200000,R=5000,worker machine=2000)


##6.备份任务机制
    一个由于某些原因（CPU，内存，本地磁盘，网络带宽）而拖后腿（执行过长的时间）的任务，拖慢了整个MapReduce操作。
    措施：当MapReduce运行接近尾声时，存在一部分worker仍在执行剩余任务时，将这一部分任务调度给其他机器备份执行。原任务和备份任务中但凡有一个完成，该任务即标记为已完成。



##7.改善
###7.1 Partitioning Function
    默认分区函数使用Hash（如hash(key) mod R），划分均衡。
    也可自定义。

###7.2 Ordering Guarantees
    确保在每个分区中，中间键值对按key升序排序。
    这样，确保每个分区产生一个排好序的输出文件；对输出文件的按key随机查找方便；用户使用也方便。

###7.3 Combiner Function
    在某些情况下，由各个Map任务产生的中间键会有大量的重复。
    如WordCount中Map任务会出现大量<the,1>，且被通过网络送往同一个Reduce任务。在网络传输之前就在Shuffle中做一些合并，可以大大减小网络传输开销。

###7.4 Input Output Types
    MapReduce库提供了对输入/输出文件多种格式的支持。（例如，"text"格式的输入将每一行作为键值对：key是文件内的偏移，value是该行的内容。）
    每一个输入/输出格式的实现都知道如何将自己进行合理的划分从而能让不同的Map任务进行处理（例如，text模式就知道将区域划分到以行为边界）。

###7.5 其它
    辅助额外输出文件、跳过坏的记录、本地执行、状态信息（Http Server状态页）、Counter






#Map-Reduce-Merge
##0.Abstract
    MapReduce不直接支持处理多重关联的混合数据集（关系型操作如join），而处理关系型数据又是一种普遍需求；
    Map-Reduce-Merge模型为MapReduce添加了一个Merge语义，可以利用map和reduce模块高效地归并已经分区和排序/哈希的数据；
    且该新模型可以表达关系型代数算子并实现了几种join算法；


##1.Introduction
    Map-Reduce-Merge通过附加的MapReduce步骤，来实现多种混合数据集的关系代数原语(如join)；
    关系型算子可以由map、reduce和merge组合而成，可以实现多个并行版本的join算法：sort-merge、hash、block nested-loop；


##2.MapReduce
###2.1 Features and Principles
    ①廉价不可靠商用硬件，而非SMP或MMP；
    ②高可扩展RAIN(Redundant Array of Independent(and Inexpensive) Nodes)集群，而非基于RAID的SAN或NAS；
    ③容错但易于管理，不想DBMS一样复杂的备份、恢复；
    ④简化且受限但强大，只关注map、reduce；
    ⑤高度并行但抽象；
    ⑥高吞吐，移动计算到数据节点；
    ⑦共享磁盘存储但不共享计算；
    ⑧面向集合的Key-Value对，文件抽象；
    ⑨函数式编程原语；
    ⑩分布式分区/排序框架；
    ⑪可应用到通用数据处理任务；

###2.2 Homogenization
    key + datasource；
    A final map/reduce task can then apply to all the homogenized datasets combined. 
    Data entries from different datasets with the same key value will be grouped in the same reduce partition.
    User-defined logic can extract data-sources from values to identify their origins, then the entries from different sources can be merged.
    只能做等值连接；


##3.Map-Reduce-Merge
    map:      (k1, v1)α                   →  [(k2, v2)]α
    reduce:   (k2, [v2])α                 →  (k2, [v3])α
    merge:    ((k2, [v3])α, (k3, [v4])β)  →  [(k4, v5)]γ
    其中α、β是dataset的lineage；
    依旧是原生的map、reduce；
    唯一的变化是：
        增加了lineage；
        (k2,[v3])而非仅仅[v3]；
    做出变化的原因是merge阶段需要输入数据按key组织(partitioned, sorted/hashed)；

###3.2 Implementation
    Merge Components：
        partition selector；
        processor function；
        merge function；
        configurable iterator；
    partition selector：
        通过merger number决定merger从哪些reducer中取数据；
        (reducer number用于决定从哪些mapper中取数据，mapper number决定取哪些输入文件的split)
        当前merger number + 两个reducer numbers集合，用户自定义的逻辑会从集合中删除不相关的reducers，只有留在集合中的reducers才会被读取并在merger中merge；
        partitionSelector.select(mergerNumber, leftReducerNumbers, rightReducerNumbers);
    processor：
        用户自定义的用于处理一个source数据的函数；
    merger:
        用户自定义处理逻辑，mapper处理一对key/value、reducer处理key-grouped value集合、merger处理两对key/values；
    configurable iterator:
        logical iterator：
            mapper：input flie split；
            reducer：a merge-sorted stream；
            merger：two logical iterators；
        a user-configurable module(iterator-manager) controls the movement of these configurable iterators；
        nested-loop、sort-merge、hash join；


##4.Applications to Relational Data Processing
###4.1 Map-Reduce-Merge Implementations of Relational Operators
    Map-Reduce-Merge是关系完备的。
    Projection：
        mapper：(k, v) -> (k', v')；
    Aggregation：
        sort-by-key、 group-by-key保证了输入到reducer是一系列(k, [v])集合，reducer可以在这个grouped value list上调用aggregate函数；
    Generalized Selection：
        如果选择条件发生在一个数据源 => 用mapper实现选择(filter)；
        如果选择条件发生在aggregate或一组values => 用reducer实现选择(filter)；
        如果选择条件发生在多个数据源的属性或aggregate => 用merger实现选择(filter)；
    Joins：
        ①Block Nested-Loop Join：
            Map：使用hash partitioner将记录分到hashed buckets中(一个bucket对应一个reducer)；
            Reduce：group and aggregate partitions using a hash table；
            Merge：nested-loop；
        ②Sort-Merge Join：
            Map：使用range partitioner将记录分到有序的buckets中(一个bucket对应一个reducer)；
            Reduce：使用外部排序(priority queue)归并成一个sorted set；
            Merge：已排序，只要merge；
        ③Hash Join：
            Map：使用hash partitioner将记录分到hashed buckets中(一个bucket对应一个reducer)；
            Reduce：group and aggregate partitions using a hash table；
            Merge：a build and a probe；
    Set Union：
        sorted and grouped，
        reducer中去重简单，merger会收到来自多个reducers的数据，需要再次去重；
    Set Intersection：
        merger iterate每个输入，并产生共同的输出；
    Set Difference：
        merger iterate每个输入，并产生difference的输出；
    Cartesian Product：
        可以用nested-loop实现；
    Rename：
        简单；

